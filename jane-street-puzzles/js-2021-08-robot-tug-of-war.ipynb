{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pontus Hultkrantz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-08: Robot Tug-of-War\n",
    "https://www.janestreet.com/puzzles/current-puzzle/\n",
    "\n",
    "The Robot Weightlifting World Championship was such a huge success that the organizers have hired you to help design its sequel: a Robot Tug-of-War Competition!\n",
    "\n",
    "In each one-on-one matchup, two robots are tied together with a rope. The center of the rope has a marker that begins above position 0 on the ground. The robots then alternate pulling on the rope. The first robot pulls in the positive direction towards 1; the second robot pulls in the negative direction towards -1. Each pull moves the marker a uniformly random draw from [0,1] towards the pulling robot. If the marker first leaves the interval [‑½,½] past ½, the first robot wins. If instead it first leaves the interval past -½, the second robot wins.\n",
    "\n",
    "However, the organizers quickly noticed that the robot going second is at a disadvantage. They want to handicap the first robot by changing the initial position of the marker on the rope to be at some negative real number. Your job is to compute the position of the marker that makes each matchup a 50-50 competition between the robots. Find this position to seven significant digits—the integrity of the Robot Tug-of-War Competition hangs in the balance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy x* = -0.2850707\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "XBOUND = 0.5 # x in (-XBOUND, XBOUND)\n",
    "X_NODES = 10+1 # Simulate x at each 0.1 interval.\n",
    "@numba.njit(parallel=False)\n",
    "def simulate(x0:float, nsim:int):\n",
    "    rvs = np.random.random\n",
    "    wins = 0\n",
    "    for i in numba.prange(int(nsim)):\n",
    "        k = -1\n",
    "        x = x0\n",
    "        while abs(x) <= XBOUND:\n",
    "            k *= -1\n",
    "            x += k*rvs()\n",
    "        if k > 0:\n",
    "            wins += 1\n",
    "    return wins / nsim\n",
    "\n",
    "nsim = int(1e6)\n",
    "xx = np.linspace(-XBOUND, XBOUND, X_NODES)\n",
    "pp = np.array([simulate(x, nsim) for x in xx])\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1,1, figsize=(10, 5))\n",
    "ax.plot(xx, pp, marker='.', color='k')\n",
    "ax.set_xlim([-XBOUND, XBOUND]); ax.set_xticks(xx)\n",
    "ax.set_ylim([0.0, 1.0]); ax.set_yticks(np.linspace(0.0, 1.0, 10+1))\n",
    "ax.set_title('Simulation of $p(x)$ where 1st player wins $W(x)\\sim Bern(p(x))$', fontsize=12)\n",
    "ax.set_xlabel('starting point x', fontsize=12)\n",
    "ax.set_ylabel('$E[\\hat{p}(x)]$', fontsize=12)\n",
    "ax.grid()\n",
    "\n",
    "mc_err = pp*(1-pp) / nsim**0.5\n",
    "ax2 = ax.twinx()\n",
    "color = 'b'\n",
    "ax2.plot(xx, mc_err, marker='.', color=color)\n",
    "ax2.ticklabel_format(style='sci',scilimits=(0,0),axis='y')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylabel('$Stdev[\\hat{p}(x)]$', fontsize=12)\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "kind = 'linear'\n",
    "p_func = interp1d(x=xx, y=pp, kind=kind)\n",
    "p_func_inv = interp1d(x=pp, y=xx, kind=kind)\n",
    "x_star = p_func_inv(0.5)\n",
    "ax.hlines(0.5, -0.5, x_star, color='lime')\n",
    "ax.vlines(x_star, 0.0, 0.5, color='lime')\n",
    "plt.show()\n",
    "\n",
    "print(f'Proxy x* = {x_star:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\hat{p}(x) \\sim \\mathcal{N}\\left(p(x), \\tfrac{p(x)\\cdot (1-p(x))}{N_{MC}}\\right)$,\n",
    "in order to get an estimation error that is less than  $\\epsilon = 10^{-7}$ with confidence $\\alpha=5\\%$ we need a minimum number of Monte Carlo simulations that obeys\n",
    "\n",
    "$\\phi^{-1}[1-\\alpha/2] \\cdot \\frac{1}{2\\sqrt{N_{MC}}} \\leq \\epsilon \\implies N_{MC} \\geq \\left(\\tfrac{1}{2\\epsilon} \\phi^{-1}[1-\\alpha/2] \\right) \\approx 10^{14}$.\n",
    "\n",
    "Using an Intel® Xeon® W-2145 Processor (8 cores, 16 threads) on Windows 10,\n",
    "one million simulations takes 3.2 ms multi-threaded (MT) and 37 ms single threaded (ST). Hence, the runtime required to reach necessary tolerance is  3.7 days (MT) and 43 days (ST).\n",
    "\n",
    "Remember that this assumes that we want to estimate p given x. In our case, we know p and need to find x, hence we need to invert the function. Since $\\tfrac{d}{dx}p(x) \\approx 1$ around $x^*$ the magnitude of the error is approximately the same for estimating $x^*= p^{-1}(0.5)$. However, we would need to run several simulations in sequence, each with an updated starting point $x$. Hence the runtime will be multiples of our original estimate, and therefore not feasible to perform in practise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $W(x)=W(x; U_1, U_2, ...) \\sim Bern(p(x))$ denote the stochatic result of a game for the first player when the game starts at position x. Then the following holds\n",
    "\n",
    "\\begin{align}\n",
    "W(x) &=  \\mathbb{1}\\left\\{U_1>\\tfrac{1}{2}-x\\right\\} + \\mathbb{1}\\left\\{U_1\\leq \\tfrac{1}{2}-x\\right\\} \\mathbb{1}\\left\\{U_2\\leq x+U_1 + \\tfrac{1}{2}\\right\\}\\cdot W(x+U_1-U_2) \\\\\n",
    "&= \\mathbb{1}\\left\\{U_1>\\tfrac{1}{2}-x\\right\\} + \\mathbb{1}\\left\\{U_1,U_2 \\in \\mathcal{R}(x)\\right\\}\\cdot W(x+U_1-U_2) \\\\\n",
    "\\end{align}\n",
    "\n",
    "In order for the first player to win, he must either win on the first turn $\\left(U_1>\\tfrac{1}{2}-x\\right)$, or else player two must not win on the second turn $\\left(U_2 \\leq x + U_1 + \\tfrac{1}{2}\\right)$, so that player one can have a new chance on turn 3; now starting at a new position $W(x+U_1-U_2)$. Furthermore, we note that $\\mathbb{P}\\left[W(\\tfrac{1}{2})=1\\right]=1$, i.e. player one surely wins if the starting position is $\\tfrac{1}{2}$, hence $\\mathbb{E}\\left[W(\\tfrac{1}{2})\\right]=1$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Taking expectations on both sides, and denoting $p(x) = \\mathbb{E}[W(x)]$\n",
    "\\begin{align}\n",
    "p(x) &= \\mathbb{P}(U_1>\\tfrac{1}{2}-x) + \\mathbb{E}\\left[\\mathbb{1}(U_1,U_2 \\in \\mathcal{R}(x))\\cdot W(x+U_1-U_2) \\right] \\\\\n",
    "&= \\tfrac{1}{2} + x + \\int_0^1 \\int_0^1\\mathbb{E}\\left[\\mathbb{1}(u_1,u_2 \\in \\mathcal{R}(x))\\cdot W(x+u_1-u_2) \\big| U_1=u_1, U_2=u_2 \\right] du_1 du_2 \\\\\n",
    "&= \\tfrac{1}{2} + x + \\int_0^1 \\int_0^1\\mathbb{1}\\{u_1,u_2 \\in \\mathcal{R}(x)\\}\\cdot \\mathbb{E}\\left[W(x+u_1-u_2; U_3, ...) \\right] du_1 du_2 \\\\\n",
    "&= \\tfrac{1}{2} + x +  \\int_0^{1/2-x} \\int_0^{1/2 + x+u_1}p(x+u_1-u_2) du_2 du_1 \\\\\n",
    "&= \\tfrac{1}{2} + x  - M(-\\tfrac{1}{2})(\\tfrac{1}{2}-x) + \\int_x^{1/2} M(s) ds \\\\\n",
    "&= \\tfrac{1}{2} + x + \\int_x^{1/2} M(s) ds,\n",
    "\\end{align}\n",
    "where $M(x):=\\int_{-1/2}^x p(s)ds$ is the primitive function of $p(x)$.\n",
    "\n",
    "\n",
    "Now differentiating both sides once and twice yield\n",
    "\\begin{align}\n",
    "p'(x) &= 1  - M(x), \\\\\n",
    "p''(x) &= -p(x).\n",
    "\\end{align}\n",
    "Together with the boundary condition $p(\\tfrac{1}{2})=1$ and ansatz $p(x) = c_1 \\sin(x) + c_2 \\cos(x)$, the system of ODEs has the solution\n",
    "\n",
    "\\begin{align}\n",
    "p(x) &= \\frac{\\sin(x) + \\cos(x)}{\\sin(1/2) + \\cos(1/2)} = \\frac{\\sin\\left(x+\\pi/4\\right)}{\\sin(1/2+\\pi/4)},\n",
    "\\end{align}\n",
    "\n",
    "where we in the last step used the identity $\\sin(\\alpha+\\beta)=\\sin(\\alpha)\\cos(\\beta) + \\cos(\\alpha)\\sin(\\beta)$.\n",
    "\n",
    "The corresponding inverted function is\n",
    "\\begin{align}\n",
    "x(p) = \\arcsin(p \\cdot \\sin(1/2+\\pi/4)) - \\pi/4,\n",
    "\\end{align}\n",
    "\n",
    "and our asnwer is given by $x(0.5) \\approx -0.2850001$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
   "language": "python",
   "name": "python37364bitprogramdatavirtualenv59ae48332b0b4b33804568dd65329faa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
